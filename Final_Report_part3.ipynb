{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flattening the Json data\n",
    "\n",
    "to flatten the data I chose to use pandas and used a slurm job array to flatten. I used pandas as it has a function called **json_normalize()** which will flatten the data. I don't believe that pyspark has this function. Dask may have it but I haven't checked.\n",
    "\n",
    "Minimum pandas version of 1.03 is required as anything below will not have **max_level** parameter necessary to split on gids.\n",
    "\n",
    "First I needed to normalize the json file to a max depth of 0 as that will create columns for each gid that contains it's own hierarchical json. Which is then transposed so that each recoding gid is it's own row/index. Metadata is then removed as the metadata contains MusicBrainz data and not spectral data. The rest is then flattened into columns and then exported to csv in this code. Or it can be set to export in parquet which is something I should have done at the beginning but I have exported it to csvs first and then later compressed it to parquet.\n",
    "\n",
    "The slurm job is done in arrays corresponding to the number of chunks of json. In this case we have 48 json chunks.\n",
    "The chunk is then divided up into processes and then joined using Queues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slurm Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --time=1:00:00\n",
    "#SBATCH -N 2\n",
    "#SBATCH -n 48\n",
    "#SBATCH -a 0-47\n",
    "\n",
    "module load python/anaconda-3.6-5.1.0\n",
    "source activate cheinu\n",
    "python clean.py $SLURM_ARRAY_TASK_ID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contents of clean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "from multiprocessing import Process, Pool, Queue, cpu_count\n",
    "\n",
    "def flatten(data, out_q):\n",
    "    #first flatten out the data into columns with \"lowlevel\", \"rhythm\", \"tonal\", \"metaData\"\n",
    "\ttempjson = json_normalize(data[0], max_level=1).set_index(data.index)\n",
    "\tdata = pd.concat([data,tempjson], axis=1)\n",
    "    #remove metadata column\n",
    "\tdata = data.drop(columns=[0, '0.metadata'])\n",
    "\t\n",
    "    #we now have the columns we want\n",
    "\tcols = ['0.lowlevel', '0.rhythm', '0.tonal']\n",
    "    \n",
    "    #now lets flatten columns \"lowlevel\", \"rhythm\", \"tonal\" jsons\n",
    "\tfor i in cols:\n",
    "\t\ttempjson = json_normalize(data[i]).set_index(data.index)\n",
    "\t\tdata = pd.concat([data,tempjson], axis=1)\n",
    "\t\tdata = data.drop(columns=[i])\n",
    "\tout_q.put(data)\n",
    "\n",
    "if __name__=='__main__':\n",
    "\tnprocs = int(os.environ[\"SLURM_CPUS_ON_NODE\"]) -16\n",
    "\tprocs = []\n",
    "\tchunknum = int(sys.argv[1])\n",
    "\t#ntasks = int(sys.argv[2])\n",
    "\tout_q = Queue()\n",
    "\n",
    "\tnewdf = pd.DataFrame()\n",
    "\n",
    "\tchunkdir = \"sbatch/data/chunk_{}.json\".format(chunknum)\n",
    "\tprint(\"opening: \", chunkdir)\n",
    "\n",
    "\twith open(chunkdir) as datafile:\n",
    "\t\tmaindata = json.load(datafile)\n",
    "\n",
    "\tmaindata = json_normalize(maindata, max_level=0).T #I have to transpose so that the gids will be in rows\n",
    "\tmaindata = maindata.reset_index()\n",
    "\n",
    "    #split for each process for a given chunk of json\n",
    "\tnewfiles = np.array_split(maindata, nprocs)\n",
    "\n",
    "\tfor i in range(nprocs):\n",
    "\t\tp = Process(target=flatten, args=(newfiles[i], out_q))\n",
    "\t\tprocs.append(p)\n",
    "\t\tp.start()\n",
    "\tfor j in range(nprocs):\n",
    "\t\tnewdf = pd.concat([newdf, out_q.get()])\n",
    "\tfor p in procs:\n",
    "\t\tp.join()\n",
    "\n",
    "    #write to csv\n",
    "\tprint(\"writing clean_{}.csv\".format(chunknum))\n",
    "\tnewdf.to_csv(\"step1/clean_{}.csv\".format(chunknum))\n",
    "\tprint(\"finished chunk_{}\".format(chunknum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample\n",
    "\n",
    "let's see what this looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0.lowlevel</th>\n",
       "      <th>0.rhythm</th>\n",
       "      <th>0.tonal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ad5b627-7687-4369-935f-e291cf22a3a2</td>\n",
       "      <td>{'average_loudness': 0.0918393954635, 'barkban...</td>\n",
       "      <td>{'beats_count': 779, 'beats_loudness': {'dmean...</td>\n",
       "      <td>{'chords_changes_rate': 0.0479620248079, 'chor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ad5f3ba-8c0c-4c99-a15f-39d85442ef07</td>\n",
       "      <td>{'average_loudness': 0.924234747887, 'barkband...</td>\n",
       "      <td>{'beats_count': 326, 'beats_loudness': {'dmean...</td>\n",
       "      <td>{'chords_changes_rate': 0.0629560127854, 'chor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ad61287-0756-469f-a9a1-1658eb0ad953</td>\n",
       "      <td>{'average_loudness': 0.778621613979, 'barkband...</td>\n",
       "      <td>{'beats_count': 623, 'beats_loudness': {'dmean...</td>\n",
       "      <td>{'chords_changes_rate': 0.0670494884253, 'chor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0ad630f5-af66-478f-930c-9b4863977851</td>\n",
       "      <td>{'average_loudness': 0.583457231522, 'barkband...</td>\n",
       "      <td>{'beats_count': 397, 'beats_loudness': {'dmean...</td>\n",
       "      <td>{'chords_changes_rate': 0.0535150393844, 'chor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ad645be-adc0-4a9c-8ed6-ba40c5868109</td>\n",
       "      <td>{'average_loudness': 0.397027939558, 'barkband...</td>\n",
       "      <td>{'beats_count': 528, 'beats_loudness': {'dmean...</td>\n",
       "      <td>{'chords_changes_rate': 0.111055441201, 'chord...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  index  \\\n",
       "0  0ad5b627-7687-4369-935f-e291cf22a3a2   \n",
       "1  0ad5f3ba-8c0c-4c99-a15f-39d85442ef07   \n",
       "2  0ad61287-0756-469f-a9a1-1658eb0ad953   \n",
       "3  0ad630f5-af66-478f-930c-9b4863977851   \n",
       "4  0ad645be-adc0-4a9c-8ed6-ba40c5868109   \n",
       "\n",
       "                                          0.lowlevel  \\\n",
       "0  {'average_loudness': 0.0918393954635, 'barkban...   \n",
       "1  {'average_loudness': 0.924234747887, 'barkband...   \n",
       "2  {'average_loudness': 0.778621613979, 'barkband...   \n",
       "3  {'average_loudness': 0.583457231522, 'barkband...   \n",
       "4  {'average_loudness': 0.397027939558, 'barkband...   \n",
       "\n",
       "                                            0.rhythm  \\\n",
       "0  {'beats_count': 779, 'beats_loudness': {'dmean...   \n",
       "1  {'beats_count': 326, 'beats_loudness': {'dmean...   \n",
       "2  {'beats_count': 623, 'beats_loudness': {'dmean...   \n",
       "3  {'beats_count': 397, 'beats_loudness': {'dmean...   \n",
       "4  {'beats_count': 528, 'beats_loudness': {'dmean...   \n",
       "\n",
       "                                             0.tonal  \n",
       "0  {'chords_changes_rate': 0.0479620248079, 'chor...  \n",
       "1  {'chords_changes_rate': 0.0629560127854, 'chor...  \n",
       "2  {'chords_changes_rate': 0.0670494884253, 'chor...  \n",
       "3  {'chords_changes_rate': 0.0535150393844, 'chor...  \n",
       "4  {'chords_changes_rate': 0.111055441201, 'chord...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "chunkdir = \"reportfiles/chunk_{}.json\".format(2)\n",
    "\n",
    "with open(chunkdir) as datafile:\n",
    "\tdata = json.load(datafile)\n",
    "\n",
    "\n",
    "data = json_normalize(data, max_level=0).T #I have to transpose so that the gids will be in rows\n",
    "data = data.reset_index()\n",
    "\n",
    "tempjson = json_normalize(data[0], max_level=1).set_index(data.index)\n",
    "data = pd.concat([data,tempjson], axis=1)\n",
    "    #remove metadata column\n",
    "data = data.drop(columns=[0, '0.metadata'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a sample and then flatten the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>average_loudness</th>\n",
       "      <th>dynamic_complexity</th>\n",
       "      <th>barkbands.dmean</th>\n",
       "      <th>barkbands.dmean2</th>\n",
       "      <th>barkbands.dvar</th>\n",
       "      <th>barkbands.dvar2</th>\n",
       "      <th>barkbands.max</th>\n",
       "      <th>barkbands.mean</th>\n",
       "      <th>barkbands.median</th>\n",
       "      <th>...</th>\n",
       "      <th>hpcp.var</th>\n",
       "      <th>hpcp_entropy.dmean</th>\n",
       "      <th>hpcp_entropy.dmean2</th>\n",
       "      <th>hpcp_entropy.dvar</th>\n",
       "      <th>hpcp_entropy.dvar2</th>\n",
       "      <th>hpcp_entropy.max</th>\n",
       "      <th>hpcp_entropy.mean</th>\n",
       "      <th>hpcp_entropy.median</th>\n",
       "      <th>hpcp_entropy.min</th>\n",
       "      <th>hpcp_entropy.var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ad5b627-7687-4369-935f-e291cf22a3a2</td>\n",
       "      <td>0.091839</td>\n",
       "      <td>8.198511</td>\n",
       "      <td>[2.10325106309e-06, 0.000234614053625, 0.00037...</td>\n",
       "      <td>[3.6466126403e-06, 0.00036908625043, 0.0006030...</td>\n",
       "      <td>[2.20399514611e-11, 3.57924079708e-07, 7.97018...</td>\n",
       "      <td>[6.72192787543e-11, 8.79129459008e-07, 2.21954...</td>\n",
       "      <td>[0.000127967898152, 0.0193108320236, 0.0170268...</td>\n",
       "      <td>[2.99578687191e-06, 0.000585605157539, 0.00079...</td>\n",
       "      <td>[9.9382850749e-07, 6.12559888395e-05, 0.000157...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0126574188471, 0.0213037766516, 0.061309915...</td>\n",
       "      <td>0.533520</td>\n",
       "      <td>0.912364</td>\n",
       "      <td>0.253803</td>\n",
       "      <td>0.650287</td>\n",
       "      <td>4.067466</td>\n",
       "      <td>1.377538</td>\n",
       "      <td>1.384897</td>\n",
       "      <td>0.033799</td>\n",
       "      <td>0.576594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ad5f3ba-8c0c-4c99-a15f-39d85442ef07</td>\n",
       "      <td>0.924235</td>\n",
       "      <td>3.281046</td>\n",
       "      <td>[0.00115961779375, 0.00764878280461, 0.0015152...</td>\n",
       "      <td>[0.00153099466115, 0.0108632184565, 0.00293669...</td>\n",
       "      <td>[6.1408595684e-06, 0.000476207846077, 7.238477...</td>\n",
       "      <td>[1.05806775537e-05, 0.00107473530807, 0.000214...</td>\n",
       "      <td>[0.0444188974798, 0.272109985352, 0.0982875227...</td>\n",
       "      <td>[0.00423845043406, 0.0225107558072, 0.00088907...</td>\n",
       "      <td>[0.00111644377466, 0.0158996060491, 2.79625237...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0443876087666, 0.0548203215003, 0.038754455...</td>\n",
       "      <td>0.640768</td>\n",
       "      <td>1.074586</td>\n",
       "      <td>0.321310</td>\n",
       "      <td>0.834083</td>\n",
       "      <td>4.614322</td>\n",
       "      <td>1.886516</td>\n",
       "      <td>1.798779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.532940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ad61287-0756-469f-a9a1-1658eb0ad953</td>\n",
       "      <td>0.778622</td>\n",
       "      <td>4.383081</td>\n",
       "      <td>[4.75470915262e-05, 0.00162874232046, 0.001055...</td>\n",
       "      <td>[7.79787224019e-05, 0.00251456839032, 0.001939...</td>\n",
       "      <td>[2.02780139347e-08, 2.40628341999e-05, 1.95965...</td>\n",
       "      <td>[4.978848267e-08, 5.21023903275e-05, 5.7101682...</td>\n",
       "      <td>[0.00339068891481, 0.128779143095, 0.063227206...</td>\n",
       "      <td>[6.14934979239e-05, 0.00231360690668, 0.000898...</td>\n",
       "      <td>[5.27273596163e-06, 0.000224814255489, 0.00013...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0772988498211, 0.04289817065, 0.03626205399...</td>\n",
       "      <td>0.622843</td>\n",
       "      <td>1.042012</td>\n",
       "      <td>0.289510</td>\n",
       "      <td>0.785070</td>\n",
       "      <td>4.553124</td>\n",
       "      <td>1.986660</td>\n",
       "      <td>2.004660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0ad630f5-af66-478f-930c-9b4863977851</td>\n",
       "      <td>0.583457</td>\n",
       "      <td>4.836153</td>\n",
       "      <td>[0.000293237942969, 0.00236392347142, 0.001721...</td>\n",
       "      <td>[0.000411182147218, 0.00382467010058, 0.002921...</td>\n",
       "      <td>[1.33503385769e-06, 6.65750776534e-05, 1.06028...</td>\n",
       "      <td>[2.5845934033e-06, 0.000163199860253, 2.944192...</td>\n",
       "      <td>[0.017749864608, 0.106422841549, 0.08857379108...</td>\n",
       "      <td>[0.000382329890272, 0.00358359701931, 0.004204...</td>\n",
       "      <td>[8.73548651725e-06, 0.0010280571878, 0.0027236...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.127469345927, 0.129632502794, 0.03104320168...</td>\n",
       "      <td>0.547933</td>\n",
       "      <td>0.920735</td>\n",
       "      <td>0.237623</td>\n",
       "      <td>0.629671</td>\n",
       "      <td>4.071524</td>\n",
       "      <td>1.839566</td>\n",
       "      <td>1.854890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ad645be-adc0-4a9c-8ed6-ba40c5868109</td>\n",
       "      <td>0.397028</td>\n",
       "      <td>3.531669</td>\n",
       "      <td>[6.2329127104e-05, 0.00209936965257, 0.0026804...</td>\n",
       "      <td>[8.90565279406e-05, 0.00349251972511, 0.004525...</td>\n",
       "      <td>[1.67730522804e-08, 1.75265286089e-05, 3.06000...</td>\n",
       "      <td>[3.14540322677e-08, 4.42475575255e-05, 7.79407...</td>\n",
       "      <td>[0.00240575056523, 0.0653672218323, 0.09743301...</td>\n",
       "      <td>[0.000134370682645, 0.00258843507618, 0.003045...</td>\n",
       "      <td>[8.84822802618e-05, 0.000910451461095, 0.00108...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0620835721493, 0.0589975118637, 0.061412181...</td>\n",
       "      <td>0.696603</td>\n",
       "      <td>1.172068</td>\n",
       "      <td>0.331266</td>\n",
       "      <td>0.888627</td>\n",
       "      <td>4.917964</td>\n",
       "      <td>2.385656</td>\n",
       "      <td>2.375285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  index  average_loudness  dynamic_complexity  \\\n",
       "0  0ad5b627-7687-4369-935f-e291cf22a3a2          0.091839            8.198511   \n",
       "1  0ad5f3ba-8c0c-4c99-a15f-39d85442ef07          0.924235            3.281046   \n",
       "2  0ad61287-0756-469f-a9a1-1658eb0ad953          0.778622            4.383081   \n",
       "3  0ad630f5-af66-478f-930c-9b4863977851          0.583457            4.836153   \n",
       "4  0ad645be-adc0-4a9c-8ed6-ba40c5868109          0.397028            3.531669   \n",
       "\n",
       "                                     barkbands.dmean  \\\n",
       "0  [2.10325106309e-06, 0.000234614053625, 0.00037...   \n",
       "1  [0.00115961779375, 0.00764878280461, 0.0015152...   \n",
       "2  [4.75470915262e-05, 0.00162874232046, 0.001055...   \n",
       "3  [0.000293237942969, 0.00236392347142, 0.001721...   \n",
       "4  [6.2329127104e-05, 0.00209936965257, 0.0026804...   \n",
       "\n",
       "                                    barkbands.dmean2  \\\n",
       "0  [3.6466126403e-06, 0.00036908625043, 0.0006030...   \n",
       "1  [0.00153099466115, 0.0108632184565, 0.00293669...   \n",
       "2  [7.79787224019e-05, 0.00251456839032, 0.001939...   \n",
       "3  [0.000411182147218, 0.00382467010058, 0.002921...   \n",
       "4  [8.90565279406e-05, 0.00349251972511, 0.004525...   \n",
       "\n",
       "                                      barkbands.dvar  \\\n",
       "0  [2.20399514611e-11, 3.57924079708e-07, 7.97018...   \n",
       "1  [6.1408595684e-06, 0.000476207846077, 7.238477...   \n",
       "2  [2.02780139347e-08, 2.40628341999e-05, 1.95965...   \n",
       "3  [1.33503385769e-06, 6.65750776534e-05, 1.06028...   \n",
       "4  [1.67730522804e-08, 1.75265286089e-05, 3.06000...   \n",
       "\n",
       "                                     barkbands.dvar2  \\\n",
       "0  [6.72192787543e-11, 8.79129459008e-07, 2.21954...   \n",
       "1  [1.05806775537e-05, 0.00107473530807, 0.000214...   \n",
       "2  [4.978848267e-08, 5.21023903275e-05, 5.7101682...   \n",
       "3  [2.5845934033e-06, 0.000163199860253, 2.944192...   \n",
       "4  [3.14540322677e-08, 4.42475575255e-05, 7.79407...   \n",
       "\n",
       "                                       barkbands.max  \\\n",
       "0  [0.000127967898152, 0.0193108320236, 0.0170268...   \n",
       "1  [0.0444188974798, 0.272109985352, 0.0982875227...   \n",
       "2  [0.00339068891481, 0.128779143095, 0.063227206...   \n",
       "3  [0.017749864608, 0.106422841549, 0.08857379108...   \n",
       "4  [0.00240575056523, 0.0653672218323, 0.09743301...   \n",
       "\n",
       "                                      barkbands.mean  \\\n",
       "0  [2.99578687191e-06, 0.000585605157539, 0.00079...   \n",
       "1  [0.00423845043406, 0.0225107558072, 0.00088907...   \n",
       "2  [6.14934979239e-05, 0.00231360690668, 0.000898...   \n",
       "3  [0.000382329890272, 0.00358359701931, 0.004204...   \n",
       "4  [0.000134370682645, 0.00258843507618, 0.003045...   \n",
       "\n",
       "                                    barkbands.median  ...  \\\n",
       "0  [9.9382850749e-07, 6.12559888395e-05, 0.000157...  ...   \n",
       "1  [0.00111644377466, 0.0158996060491, 2.79625237...  ...   \n",
       "2  [5.27273596163e-06, 0.000224814255489, 0.00013...  ...   \n",
       "3  [8.73548651725e-06, 0.0010280571878, 0.0027236...  ...   \n",
       "4  [8.84822802618e-05, 0.000910451461095, 0.00108...  ...   \n",
       "\n",
       "                                            hpcp.var hpcp_entropy.dmean  \\\n",
       "0  [0.0126574188471, 0.0213037766516, 0.061309915...           0.533520   \n",
       "1  [0.0443876087666, 0.0548203215003, 0.038754455...           0.640768   \n",
       "2  [0.0772988498211, 0.04289817065, 0.03626205399...           0.622843   \n",
       "3  [0.127469345927, 0.129632502794, 0.03104320168...           0.547933   \n",
       "4  [0.0620835721493, 0.0589975118637, 0.061412181...           0.696603   \n",
       "\n",
       "   hpcp_entropy.dmean2  hpcp_entropy.dvar  hpcp_entropy.dvar2  \\\n",
       "0             0.912364           0.253803            0.650287   \n",
       "1             1.074586           0.321310            0.834083   \n",
       "2             1.042012           0.289510            0.785070   \n",
       "3             0.920735           0.237623            0.629671   \n",
       "4             1.172068           0.331266            0.888627   \n",
       "\n",
       "   hpcp_entropy.max  hpcp_entropy.mean  hpcp_entropy.median  hpcp_entropy.min  \\\n",
       "0          4.067466           1.377538             1.384897          0.033799   \n",
       "1          4.614322           1.886516             1.798779          0.000000   \n",
       "2          4.553124           1.986660             2.004660          0.000000   \n",
       "3          4.071524           1.839566             1.854890          0.000000   \n",
       "4          4.917964           2.385656             2.375285          0.000000   \n",
       "\n",
       "   hpcp_entropy.var  \n",
       "0          0.576594  \n",
       "1          0.532940  \n",
       "2          0.767897  \n",
       "3          0.504924  \n",
       "4          0.676673  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[0:10]\n",
    "    #we now have the columns we want\n",
    "cols = ['0.lowlevel', '0.rhythm', '0.tonal']\n",
    "    \n",
    "    #now lets flatten columns \"lowlevel\", \"rhythm\", \"tonal\" jsons\n",
    "for i in cols:\n",
    "\ttempjson = json_normalize(data[i]).set_index(data.index)\n",
    "\tdata = pd.concat([data,tempjson], axis=1)\n",
    "\tdata = data.drop(columns=[i])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then Export the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressor (optional)\n",
    "Initially I made the mistake of exporting to csvs and not parquet directly so below is the optional code to compress everything into parquets using slurm arrays. It's pretty straightforward so I won't explain what's going on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slurm Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --time=00:05:00\n",
    "#SBATCH -N 1\n",
    "#SBATCH -n 2 \n",
    "#SBATCH -a 0-47\n",
    "\n",
    "#. /global/software/jupyterhub-spark/anaconda3/etc/profile.d/conda.sh\n",
    "\n",
    "#which python\n",
    "#which conda\n",
    "\n",
    ". /global/software/anaconda/anaconda-3.6-5.1.0/etc/profile.d/conda.sh\n",
    "module load python/anaconda-3.6-5.1.0\n",
    "conda activate cheinu\n",
    "\n",
    "python compressor.py $SLURM_ARRAY_TASK_ID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contents of compressor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import pandas as pd\n",
    "\n",
    "print(pd.__version__)\n",
    "if __name__==\"__main__\":\n",
    "\tchunk = int(sys.argv[1])\n",
    "\tprint(chunk)\n",
    "\tfdir = '../step1/clean_{}.csv'.format(chunk)\n",
    "\tdf = pd.read_csv(fdir).drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "\tdf.to_parquet('../step1/clean_{}.parquet'.format(chunk), compression='snappy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
